{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /opt/manual/spark: this is SPARK_HOME path\n",
    "findspark.init(\"/opt/manual/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/manual/spark-3.1.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "2022-08-27 20:05:06,036 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    ".appName(\"Review Execution Plan\") \\\n",
    ".master(\"local[2]\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source: https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget -P ~/datasets \\\n",
    "#https://github.com/erkansirin78/datasets/raw/master/Hotel_Reviews.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r--. 1 train train 46401315 Aug 27 11:25 Hotel_Reviews.csv.gz\n"
     ]
    }
   ],
   "source": [
    "! ls -l ~/datasets | grep Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "programmatical_schema = StructType([\n",
    "        StructField(\"Hotel_Address\",StringType(),True),\n",
    "        StructField(\"Additional_Number_of_Scoring\",IntegerType(),True),\n",
    "        StructField(\"Review_Date\",StringType(),True),\n",
    "        StructField(\"Average_Score\",FloatType(),True),\n",
    "        StructField(\"Hotel_Name\",StringType(),True),\n",
    "        StructField(\"Reviewer_Nationality\",StringType(),True),\n",
    "        StructField(\"Negative_Review\",StringType(),True),\n",
    "        StructField(\"Review_Total_Negative_Word_Counts\",IntegerType(),True),\n",
    "        StructField(\"Total_Number_of_Reviews\",IntegerType(),True),\n",
    "        StructField(\"Positive_Review\",StringType(),True),\n",
    "        StructField(\"Review_Total_Positive_Word_Counts\",IntegerType(),True),\n",
    "        StructField(\"Total_Number_of_Reviews_Reviewer_Has_Given\",IntegerType(),True),\n",
    "        StructField(\"Reviewer_Score\",FloatType(),True),\n",
    "        StructField(\"Tags\",StringType(),True),\n",
    "        StructField(\"days_since_review\",StringType(),True),\n",
    "        StructField(\"lat\",FloatType(),True),\n",
    "        StructField(\"lng\",FloatType(),True)\n",
    "    ])\n",
    "\n",
    "# StructField(\"Tags\",ArrayType(StringType()),True)\n",
    "# Actually Tags should be array but csv cannot store array type.\n",
    "# So you have to define it as StringType \n",
    "\n",
    "# Review_Date is still StringType() and should be DateType() \n",
    "# But for the moment we intentioally leave it StringType()\n",
    "# As soon as we put schema on data we will modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", True) \\\n",
    ".schema(programmatical_schema) \\\n",
    ".option(\"compression\",\"gzip\") \\\n",
    ".csv(\"file:///home/train/datasets/Hotel_Reviews.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can correct Tags datatype\n",
    "# But we have to do additional preperation before cast with split.\n",
    "# And cast Review_Date to date\n",
    "df2 = df.withColumn(\"Tags\", \n",
    "                     F.split(F.col(\"Tags\"), \",\")\n",
    "                     .cast(ArrayType(StringType()))) \\\n",
    ".withColumn(\"Review_Date\", F.to_date(F.col(\"Review_Date\"),\"M/d/yyyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------------------+\n",
      "|Day_of_Review|Total_Reviews|AVG_Reviewer_Score|\n",
      "+-------------+-------------+------------------+\n",
      "|          Tue|       120948| 8.444183518088053|\n",
      "|          Wed|        58591| 8.405661343067354|\n",
      "|          Mon|        81145| 8.392337241050269|\n",
      "|          Sun|        83981| 8.390862285826119|\n",
      "|          Fri|        44732| 8.373535788875781|\n",
      "|          Sat|        51833| 8.371462261789713|\n",
      "|          Thu|        74508| 8.344132239579093|\n",
      "+-------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What if we want to day names instead of day number\n",
    "df2.select('Review_Date', F.date_format('Review_Date', 'E').alias('Day_of_Review'), \n",
    "           'Reviewer_Score') \\\n",
    ".groupBy('Day_of_Review') \\\n",
    ".agg(F.count('*').alias(\"Total_Reviews\"), F.avg('Reviewer_Score').alias(\"AVG_Reviewer_Score\")) \\\n",
    ".orderBy(F.desc('AVG_Reviewer_Score')) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/spark_computaion_journey.png\"/>\n",
    "\n",
    "<p>Source: Learning Spark, O'Reilly, 2020</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/spark_example_query_plan.png\"/>\n",
    "\n",
    "<p>Source: Learning Spark, O'Reilly, 2020 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.select('Review_Date', F.date_format('Review_Date', 'E').alias('Day_of_Review'), \n",
    "           'Reviewer_Score') \\\n",
    ".groupBy('Day_of_Review') \\\n",
    ".agg(F.count('*').alias(\"Total_Reviews\"), F.avg('Reviewer_Score').alias(\"AVG_Reviewer_Score\")) \\\n",
    ".orderBy(F.desc('AVG_Reviewer_Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['AVG_Reviewer_Score DESC NULLS LAST], true\n",
      "+- Aggregate [Day_of_Review#105], [Day_of_Review#105, count(1) AS Total_Reviews#113L, avg(cast(Reviewer_Score#12 as double)) AS AVG_Reviewer_Score#115]\n",
      "   +- Project [Review_Date#52, date_format(cast(Review_Date#52 as timestamp), E, Some(Europe/Istanbul)) AS Day_of_Review#105, Reviewer_Score#12]\n",
      "      +- Project [Hotel_Address#0, Additional_Number_of_Scoring#1, to_date('Review_Date, Some(M/d/yyyy)) AS Review_Date#52, Average_Score#3, Hotel_Name#4, Reviewer_Nationality#5, Negative_Review#6, Review_Total_Negative_Word_Counts#7, Total_Number_of_Reviews#8, Positive_Review#9, Review_Total_Positive_Word_Counts#10, Total_Number_of_Reviews_Reviewer_Has_Given#11, Reviewer_Score#12, Tags#34, days_since_review#14, lat#15, lng#16]\n",
      "         +- Project [Hotel_Address#0, Additional_Number_of_Scoring#1, Review_Date#2, Average_Score#3, Hotel_Name#4, Reviewer_Nationality#5, Negative_Review#6, Review_Total_Negative_Word_Counts#7, Total_Number_of_Reviews#8, Positive_Review#9, Review_Total_Positive_Word_Counts#10, Total_Number_of_Reviews_Reviewer_Has_Given#11, Reviewer_Score#12, cast(split(Tags#13, ,, -1) as array<string>) AS Tags#34, days_since_review#14, lat#15, lng#16]\n",
      "            +- Relation[Hotel_Address#0,Additional_Number_of_Scoring#1,Review_Date#2,Average_Score#3,Hotel_Name#4,Reviewer_Nationality#5,Negative_Review#6,Review_Total_Negative_Word_Counts#7,Total_Number_of_Reviews#8,Positive_Review#9,Review_Total_Positive_Word_Counts#10,Total_Number_of_Reviews_Reviewer_Has_Given#11,Reviewer_Score#12,Tags#13,days_since_review#14,lat#15,lng#16] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Day_of_Review: string, Total_Reviews: bigint, AVG_Reviewer_Score: double\n",
      "Sort [AVG_Reviewer_Score#115 DESC NULLS LAST], true\n",
      "+- Aggregate [Day_of_Review#105], [Day_of_Review#105, count(1) AS Total_Reviews#113L, avg(cast(Reviewer_Score#12 as double)) AS AVG_Reviewer_Score#115]\n",
      "   +- Project [Review_Date#52, date_format(cast(Review_Date#52 as timestamp), E, Some(Europe/Istanbul)) AS Day_of_Review#105, Reviewer_Score#12]\n",
      "      +- Project [Hotel_Address#0, Additional_Number_of_Scoring#1, to_date('Review_Date, Some(M/d/yyyy)) AS Review_Date#52, Average_Score#3, Hotel_Name#4, Reviewer_Nationality#5, Negative_Review#6, Review_Total_Negative_Word_Counts#7, Total_Number_of_Reviews#8, Positive_Review#9, Review_Total_Positive_Word_Counts#10, Total_Number_of_Reviews_Reviewer_Has_Given#11, Reviewer_Score#12, Tags#34, days_since_review#14, lat#15, lng#16]\n",
      "         +- Project [Hotel_Address#0, Additional_Number_of_Scoring#1, Review_Date#2, Average_Score#3, Hotel_Name#4, Reviewer_Nationality#5, Negative_Review#6, Review_Total_Negative_Word_Counts#7, Total_Number_of_Reviews#8, Positive_Review#9, Review_Total_Positive_Word_Counts#10, Total_Number_of_Reviews_Reviewer_Has_Given#11, Reviewer_Score#12, cast(split(Tags#13, ,, -1) as array<string>) AS Tags#34, days_since_review#14, lat#15, lng#16]\n",
      "            +- Relation[Hotel_Address#0,Additional_Number_of_Scoring#1,Review_Date#2,Average_Score#3,Hotel_Name#4,Reviewer_Nationality#5,Negative_Review#6,Review_Total_Negative_Word_Counts#7,Total_Number_of_Reviews#8,Positive_Review#9,Review_Total_Positive_Word_Counts#10,Total_Number_of_Reviews_Reviewer_Has_Given#11,Reviewer_Score#12,Tags#13,days_since_review#14,lat#15,lng#16] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [AVG_Reviewer_Score#115 DESC NULLS LAST], true\n",
      "+- Aggregate [Day_of_Review#105], [Day_of_Review#105, count(1) AS Total_Reviews#113L, avg(cast(Reviewer_Score#12 as double)) AS AVG_Reviewer_Score#115]\n",
      "   +- Project [date_format(cast(cast(gettimestamp(Review_Date#2, M/d/yyyy, Some(Europe/Istanbul), false) as date) as timestamp), E, Some(Europe/Istanbul)) AS Day_of_Review#105, Reviewer_Score#12]\n",
      "      +- Relation[Hotel_Address#0,Additional_Number_of_Scoring#1,Review_Date#2,Average_Score#3,Hotel_Name#4,Reviewer_Nationality#5,Negative_Review#6,Review_Total_Negative_Word_Counts#7,Total_Number_of_Reviews#8,Positive_Review#9,Review_Total_Positive_Word_Counts#10,Total_Number_of_Reviews_Reviewer_Has_Given#11,Reviewer_Score#12,Tags#13,days_since_review#14,lat#15,lng#16] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(3) Sort [AVG_Reviewer_Score#115 DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(AVG_Reviewer_Score#115 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#56]\n",
      "   +- *(2) HashAggregate(keys=[Day_of_Review#105], functions=[count(1), avg(cast(Reviewer_Score#12 as double))], output=[Day_of_Review#105, Total_Reviews#113L, AVG_Reviewer_Score#115])\n",
      "      +- Exchange hashpartitioning(Day_of_Review#105, 200), ENSURE_REQUIREMENTS, [id=#52]\n",
      "         +- *(1) HashAggregate(keys=[Day_of_Review#105], functions=[partial_count(1), partial_avg(cast(Reviewer_Score#12 as double))], output=[Day_of_Review#105, count#122L, sum#123, count#124L])\n",
      "            +- *(1) Project [date_format(cast(cast(gettimestamp(Review_Date#2, M/d/yyyy, Some(Europe/Istanbul), false) as date) as timestamp), E, Some(Europe/Istanbul)) AS Day_of_Review#105, Reviewer_Score#12]\n",
      "               +- FileScan csv [Review_Date#2,Reviewer_Score#12] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/home/train/datasets/Hotel_Reviews.csv.gz], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Review_Date:string,Reviewer_Score:float>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvspark",
   "language": "python",
   "name": "venvspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
